{
  "0": {
    "doc": "Create a project in Ingest",
    "title": "Create a project in ingest",
    "content": " ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#create-a-project-in-ingest",
    "relUrl": "/docs/create_a_project/create_a_project.html#create-a-project-in-ingest"
  },
  "1": {
    "doc": "Create a project in Ingest",
    "title": "Purpose of this document",
    "content": "This document is intended to give an introduction to the HCA ingest service, specifically targeting data and metadata in the system and how they interact in the ingest ecosystem of data. These documents will be coupled with a set of python notebooks, which will show examples of how to interact with the data. This is the create a project doc, which will explain how to create, modify and delete a project in ingest. ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#purpose-of-this-document",
    "relUrl": "/docs/create_a_project/create_a_project.html#purpose-of-this-document"
  },
  "2": {
    "doc": "Create a project in Ingest",
    "title": "Table of contents",
    "content": ". | Step by step . | Static view (HTML render) | Interactive view (Notebook) | . | Understanding the metadata . | Schema fields | . | Creating your own project metadata . | The project metadata schema | . | Project metadata peculiarities | . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#table-of-contents",
    "relUrl": "/docs/create_a_project/create_a_project.html#table-of-contents"
  },
  "3": {
    "doc": "Create a project in Ingest",
    "title": "Step by step",
    "content": "In this section, a rendering of a python notebook showing the steps to create a project, step by step, can be expanded from below. Static view (HTML render) . Project notebook (HTML render) Untitled0 . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#step-by-step",
    "relUrl": "/docs/create_a_project/create_a_project.html#step-by-step"
  },
  "4": {
    "doc": "Create a project in Ingest",
    "title": "Programmatic Submissions to Ingest&#182;",
    "content": "see ticket 834 . This notebook is intended to give an insight into how to generate a submission by using the python tools available, the hca-ingest library. This library, amongst other utilities for interacting with the Ingest service, contains a wrapper for Ingest's API, which lets you easily create, update and delete . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Programmatic-Submissions-to-Ingest",
    "relUrl": "/docs/create_a_project/create_a_project.html#Programmatic-Submissions-to-Ingest"
  },
  "5": {
    "doc": "Create a project in Ingest",
    "title": "Clone git repository&#182;",
    "content": "In order to have the files necessary for this guide, we're going to clone the repository to this location, and we're going to use the repo as our base folder. In&nbsp;[&nbsp;]: !git clone https://github.com/ebi-ait/hca-ebi-dev-team.git %cd hca-ebi-dev-team/ !git checkout feature/dcp-834-programmatic-submissions !git pull origin feature/dcp-834-programmatic-submissions . Cloning into &#39;hca-ebi-dev-team&#39;... remote: Enumerating objects: 3071, done. remote: Counting objects: 100% (462/462), done. remote: Compressing objects: 100% (294/294), done. remote: Total 3071 (delta 287), reused 279 (delta 161), pack-reused 2609 Receiving objects: 100% (3071/3071), 43.12 MiB | 15.36 MiB/s, done. Resolving deltas: 100% (1831/1831), done. Checking out files: 100% (263/263), done. /content/hca-ebi-dev-team Branch &#39;feature/dcp-834-programmatic-submissions&#39; set up to track remote branch &#39;feature/dcp-834-programmatic-submissions&#39; from &#39;origin&#39;. Switched to a new branch &#39;feature/dcp-834-programmatic-submissions&#39; From https://github.com/ebi-ait/hca-ebi-dev-team * branch feature/dcp-834-programmatic-submissions -&gt; FETCH_HEAD Already up to date. ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Clone-git-repository",
    "relUrl": "/docs/create_a_project/create_a_project.html#Clone-git-repository"
  },
  "6": {
    "doc": "Create a project in Ingest",
    "title": "Set up  libraries and dependencies&#182;",
    "content": "Install external libraries&#182; . In&nbsp;[&nbsp;]: !pip install hca-ingest . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Collecting hca-ingest Downloading hca-ingest-2.3.0.tar.gz (58 kB) |████████████████████████████████| 58 kB 2.8 MB/s Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (1.4.4) Collecting attrs==21.4.0 Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB) |████████████████████████████████| 60 kB 6.2 MB/s Collecting cattrs==22.1.0 Downloading cattrs-22.1.0-py3-none-any.whl (33 kB) Requirement already satisfied: certifi==2022.6.15 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (2022.6.15) Requirement already satisfied: cffi==1.15.1 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (1.15.1) Collecting charset-normalizer==2.1.0 Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB) Collecting cryptography==37.0.4 Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB) |████████████████████████████████| 4.1 MB 38.8 MB/s Collecting dataclasses==0.6 Downloading dataclasses-0.6-py3-none-any.whl (14 kB) Requirement already satisfied: et-xmlfile==1.1.0 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (1.1.0) Collecting exceptiongroup==1.0.0rc8 Downloading exceptiongroup-1.0.0rc8-py3-none-any.whl (11 kB) Collecting idna==3.3 Downloading idna-3.3-py3-none-any.whl (61 kB) |████████████████████████████████| 61 kB 7.7 MB/s Collecting jsonref==0.2 Downloading jsonref-0.2-py3-none-any.whl (9.3 kB) Collecting mergedeep==1.3.4 Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB) Requirement already satisfied: openpyxl==3.0.10 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (3.0.10) Collecting polling==0.3.2 Downloading polling-0.3.2.tar.gz (5.2 kB) Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (2.21) Collecting pyjwt==2.4.0 Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB) Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (6.0) Collecting requests[security]==2.28.1 Downloading requests-2.28.1-py3-none-any.whl (62 kB) |████████████████████████████████| 62 kB 1.5 MB/s Collecting requests-cache==0.9.5 Downloading requests_cache-0.9.5-py3-none-any.whl (47 kB) |████████████████████████████████| 47 kB 4.7 MB/s Collecting six==1.16.0 Downloading six-1.16.0-py2.py3-none-any.whl (11 kB) Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.7/dist-packages (from hca-ingest) (2.4.0) Collecting url-normalize==1.4.3 Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB) Collecting urllib3==1.26.11 Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB) |████████████████████████████████| 139 kB 42.8 MB/s Collecting xlsxwriter==3.0.3 Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB) |████████████████████████████████| 149 kB 39.5 MB/s Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from cattrs==22.1.0-&gt;hca-ingest) (4.1.1) Requirement already satisfied: requests&lt;3.0,&gt;=2.22 in /usr/local/lib/python3.7/dist-packages (from requests-cache==0.9.5-&gt;hca-ingest) (2.23.0) Building wheels for collected packages: hca-ingest, polling Building wheel for hca-ingest (setup.py) ... done Created wheel for hca-ingest: filename=hca_ingest-2.3.0-py3-none-any.whl size=72726 sha256=04d885c40ae1cafe38033d572adb6e6232c1d9d804093163280b13e651021e51 Stored in directory: /root/.cache/pip/wheels/2b/9d/96/be434232e5d79c55550f78ce3af8db2bf67a60dcdc907e3b0e Building wheel for polling (setup.py) ... done Created wheel for polling: filename=polling-0.3.2-py3-none-any.whl size=4129 sha256=80c8f9603c8f868808f6987773bdff239f6feb82e576290f20fd26d34457849f Stored in directory: /root/.cache/pip/wheels/e5/3f/0c/54a03b715fce3176335c957ae94d7d0b2a918e89b1b195bace Successfully built hca-ingest polling Installing collected packages: urllib3, six, idna, exceptiongroup, charset-normalizer, attrs, url-normalize, requests, cattrs, xlsxwriter, requests-cache, pyjwt, polling, mergedeep, jsonref, dataclasses, cryptography, hca-ingest Attempting uninstall: urllib3 Found existing installation: urllib3 1.24.3 Uninstalling urllib3-1.24.3: Successfully uninstalled urllib3-1.24.3 Attempting uninstall: six Found existing installation: six 1.15.0 Uninstalling six-1.15.0: Successfully uninstalled six-1.15.0 Attempting uninstall: idna Found existing installation: idna 2.10 Uninstalling idna-2.10: Successfully uninstalled idna-2.10 Attempting uninstall: charset-normalizer Found existing installation: charset-normalizer 2.1.1 Uninstalling charset-normalizer-2.1.1: Successfully uninstalled charset-normalizer-2.1.1 Attempting uninstall: attrs Found existing installation: attrs 22.1.0 Uninstalling attrs-22.1.0: Successfully uninstalled attrs-22.1.0 Attempting uninstall: requests Found existing installation: requests 2.23.0 Uninstalling requests-2.23.0: Successfully uninstalled requests-2.23.0 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. ipython 7.9.0 requires jedi&gt;=0.10, which is not installed. Successfully installed attrs-21.4.0 cattrs-22.1.0 charset-normalizer-2.1.0 cryptography-37.0.4 dataclasses-0.6 exceptiongroup-1.0.0rc8 hca-ingest-2.3.0 idna-3.3 jsonref-0.2 mergedeep-1.3.4 polling-0.3.2 pyjwt-2.4.0 requests-2.28.1 requests-cache-0.9.5 six-1.16.0 url-normalize-1.4.3 urllib3-1.26.11 xlsxwriter-3.0.3 . Load libraries&#182; . In&nbsp;[&nbsp;]: import requests as rq import json from hca_ingest.api.ingestapi import IngestApi . Get a token&#182; . In order to get a token, you need to log in to the ingest UI: https://staging.contribute.data.humancellatlas.org/. For the purpose of this notebook, we will be using staging. However, that can be change to prod (by deleting the first part of the domain) or to dev (by changing staging to dev) at any point in the process. If you are going to use any other environment, please remember to change the environment variable in the next section . The steps to obtain the token are as follows: . | Log in the Ingest UI | Get to the developer tools; in google chrome, you can achieve that by clicking on the 3 dots on the top-right corner → more tools → developer tools | On the new screen, go to Application → local storage → url of the UI → key: oidc.user... → copy value of access token | . Once obtained, you can paste it in the code below, making sure the string always follows the format &quot;Bearer &lt;access_token&gt;&quot; . In&nbsp;[&nbsp;]: # TODO: for now token is obtained from the UI token = &quot;Bearer eyJraWQiOiJyc2ExIiwidHlwIjoiSldUIiwiYWxnIjoiUlMyNTYifQ.eyJzdWIiOiIyNjMwM2NiY2QzYWI2ZTAxOTdkZThkNTYzZDYzODNkMWU5NWM4ZTM1QGVsaXhpci1ldXJvcGUub3JnIiwiYXpwIjoiZTIwNDFjMmQtOTQ0OS00NDY4LTg1NmUtZTg0NzExY2ViZDIxIiwic2NvcGUiOiJlbWFpbCBvcGVuaWQgcHJvZmlsZSIsImlzcyI6Imh0dHBzOi8vbG9naW4uZWxpeGlyLWN6ZWNoLm9yZy9vaWRjLyIsImV4cCI6MTY2Mjk5NjAwNSwiaWF0IjoxNjYyOTgxNjA1LCJqdGkiOiI5MDAzN2QwNi0yYzI1LTQ5YjgtYThlYi1mMTQzODM3NjAzZTQifQ.jynGpOIL2fPKzhmQxUD0OLrB4SIRWw4mARWBTMARjiGclbc3ypulROMEr76fMHn-P19TMi6GJXZD_cdhBQ_NGVoSylLdRezv5DvghulS6pCL2WExDxXFJ0ecaIHDFlPC5iHWVQUmOvT-t0rqBLD83gXRpkxm0glibBCdnf99ozZmuUe1dfzPsLYeLBP62niWm6gt2508RjsZj33OvwS2ddYG_9qX4Gg277q6jwoJfnswLcQxAL3_y4uJwG9nMm1V_ztSLmiZnX6M9c6AVT5S_KYTeGSQGGJsJWBY6F4CRsoiTCSDY6_01PfytE_CHbDqLT0p1hiPCPKuT7EtSCgSew&quot; . Set up environment and global variables&#182; . In&nbsp;[&nbsp;]: # Environment-related set-up and global variables used across the notebook accepted_environments = { &#39;develop&#39;: &#39;.dev&#39;, &#39;staging&#39;: &#39;.staging&#39;, &#39;production&#39;: &#39;&#39; } environment = &#39;staging&#39; #staging environment by default # Set up environment value for API&#39;s URL try: env_for_url = accepted_environments[environment] except KeyError: print(f&quot;Environment {environment} not recognised. Defaulting to staging&quot;) env_for_url = accepted_environments[&#39;staging&#39;] base_url = f&#39;https://api.ingest{env_for_url}.archive.data.humancellatlas.org&#39; # Set up API object api = IngestApi(url=base_url) headers = api.set_token(token=token) . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Set-up--libraries-and-dependencies",
    "relUrl": "/docs/create_a_project/create_a_project.html#Set-up--libraries-and-dependencies"
  },
  "7": {
    "doc": "Create a project in Ingest",
    "title": "Create a project&#182;",
    "content": "This block of code will be dedicated to creating a project within ingest. The following will be assumed: . | A JSON entity is available for use as the &quot;content&quot; | . For the purpose of this notebook, everything will be performed in the staging environment. To perform this on other environments (e.g. prod), please update the environment variable to any of the values accepted in accepted_environments . In&nbsp;[&nbsp;]: # Load the project metadata entity with open(&#39;/content/hca-ebi-dev-team/scripts/programmatic_submissions/example_submission/project/example_project.json&#39;, &#39;r&#39;) as f: project_content = json.load(f) # TODO: delete requirement for submission in create_project function. ingest_project = api.create_project(submission_url=&#39;&#39;, content=project_content) . The returned object is the project as contained by ingest: this object contains the metadata that was submitted in the previous step, but also contains some extra, important metadata: . | uuid: Unique identifier for your project, generated randomly | Management metadata: This metadata comprises metadata that will apply to your experiment, e.g. organs, species used, etc. | . We're going to print the object and take a look . In&nbsp;[&nbsp;]: ingest_project . Out[&nbsp;]: {&#39;content&#39;: {&#39;describedBy&#39;: &#39;https://schema.staging.data.humancellatlas.org/type/project/17.0.0/project&#39;, &#39;schema_type&#39;: &#39;project&#39;, &#39;project_core&#39;: {&#39;project_short_name&#39;: &#39;myCoolLabel&#39;, &#39;project_title&#39;: &#39;Test_project_with_minimum_information&#39;, &#39;project_description&#39;: &#39;This is a test project with minimum information for the programmatic submissions guide&#39;}, &#39;contributors&#39;: [{&#39;name&#39;: &#39;Enrique,,Ventura&#39;, &#39;email&#39;: &#39;enrique@ebi.ac.uk&#39;, &#39;institution&#39;: &#39;EMBL-EBI&#39;, &#39;corresponding_contributor&#39;: True, &#39;project_role&#39;: {&#39;text&#39;: &#39;data curator&#39;, &#39;ontology&#39;: &#39;EFO:0009737&#39;, &#39;ontology_label&#39;: &#39;data curator&#39;}}], &#39;publications&#39;: [{&#39;authors&#39;: [&#39;Lorem IP&#39;, &#39;Sed UP&#39;], &#39;title&#39;: &#39;A combined approach for single-cell mRNA and intracellular protein expression analysis&#39;, &#39;url&#39;: &#39;https://www.frontiersin.org/articles/10.3389/fcell.2020.00384/full&#39;, &#39;official_hca_publication&#39;: False}], &#39;funders&#39;: [{&#39;grant_title&#39;: &#39;a cool grant&#39;, &#39;grant_id&#39;: &#39;000000000bp1&#39;, &#39;organization&#39;: &#39;EMBL-EBI&#39;}]}, &#39;submissionDate&#39;: &#39;2022-09-12T11:20:46.006274Z&#39;, &#39;updateDate&#39;: &#39;2022-09-12T11:20:46.006274Z&#39;, &#39;user&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;lastModifiedUser&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;type&#39;: &#39;Project&#39;, &#39;uuid&#39;: {&#39;uuid&#39;: &#39;dd576596-a8a4-41c1-b402-c46a4ca04395&#39;}, &#39;events&#39;: [], &#39;firstDcpVersion&#39;: &#39;2022-09-12T11:20:46.006274Z&#39;, &#39;dcpVersion&#39;: &#39;2022-09-12T11:20:46.006274Z&#39;, &#39;contentLastModified&#39;: &#39;2022-09-12T11:20:46.004085Z&#39;, &#39;accession&#39;: None, &#39;validationState&#39;: &#39;Draft&#39;, &#39;validationErrors&#39;: None, &#39;graphValidationErrors&#39;: None, &#39;isUpdate&#39;: False, &#39;releaseDate&#39;: None, &#39;accessionDate&#39;: None, &#39;technology&#39;: None, &#39;organ&#39;: None, &#39;cellCount&#39;: None, &#39;dataAccess&#39;: None, &#39;identifyingOrganisms&#39;: None, &#39;primaryWrangler&#39;: None, &#39;secondaryWrangler&#39;: None, &#39;wranglingState&#39;: None, &#39;wranglingPriority&#39;: None, &#39;wranglingNotes&#39;: None, &#39;isInCatalogue&#39;: None, &#39;cataloguedDate&#39;: None, &#39;publicationsInfo&#39;: None, &#39;dcpReleaseNumber&#39;: None, &#39;projectLabels&#39;: None, &#39;hasOpenSubmission&#39;: False, &#39;_links&#39;: {&#39;self&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;}, &#39;project&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;, &#39;title&#39;: &#39;A single project&#39;}, &#39;validating&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/validatingEvent&#39;}, &#39;bundleManifests&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/bundleManifests&#39;, &#39;title&#39;: &#39;Access or create bundle manifests (describing which submitted contents went into which bundle in the datastore)&#39;}, &#39;auditLogs&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/auditLogs&#39;}, &#39;supplementaryFiles&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/supplementaryFiles&#39;}, &#39;submissionEnvelopes&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelopes&#39;, &#39;title&#39;: &#39;Access or create new submission envelopes&#39;}, &#39;submissionEnvelope&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelope&#39;, &#39;title&#39;: &#39;A single submission envelope&#39;}}} . Everything looks correct, so we will save the identifier for our project (called the uuid) and store it in case we need to retrieve the project later. In&nbsp;[&nbsp;]: # Store project uuid ingest_project_uuid = ingest_project[&#39;uuid&#39;][&#39;uuid&#39;] . Understanding the information on the project&#182; . After printing the resulting ingest_project, you probably have noticed that there is much more meatadata than what was sent; for most entities, this is just system-generated and you don't need to worry about it. However, for project metadata, we load some information regarding statuses and general-level metadata for different purposes (e.g. display in the project catalogue). This project-level metadata is explained in more detail in the readme file of this notebook. For now, we will focus on the metadata that we should fill out: . In&nbsp;[&nbsp;]: minimum_required_fields = { &#39;releaseDate&#39;: None, # Date that you want your data to be released. If the data is to be released as soon as possible, or if data has already been released (e.g. in GEO) input today&#39;s date in format: YYYY-MM-DDT00:00:00Z (e.g. 2021-11-29T00:00:00Z) &#39;accessionDate&#39;: None, # Same as above, but for accessioning in public archives. &#39;technology&#39;: None, # Library preparation technology(ies) used in the experiment, ontologised. More below. &#39;organ&#39;: None, # Organ(s) used in the experimnt, ontologised. More below &#39;cellCount&#39;: None, # Estimated number of cells generated by this project. &#39;dataAccess&#39;: None, # Type of data access, selected from a list of terms. For more detail, refer to readme. &#39;identifyingOrganisms&#39;: None, # Organism that was used to generate the data, can be: Human, Mouse, or both. &#39;primaryWrangler&#39;: None, # Person that is in charge of the project/submission: associated with a user. &#39;wranglingState&#39;: None, # Status of the project. For a detailed list of accepted values, refer to readme. &#39;wranglingPriority&#39;: None, # 1, 2, or 3. 1 is highest priority and 3 is lowest. Refer to readme for more information. &#39;wranglingNotes&#39;: None, # Extra notes associated with the project; feel free to input your own notes here. &#39;isInCatalogue&#39;: None, # If the project is to be displayed in the catalogue, True, otherwise False } . Adding minimum information&#182; . Now, we will be modifying the information on the list above, to make sure we enter the minimum amount of metadata that the project should contain. We're going to divide the fields in 2 types: . | Ontologised: fields that are validated against the HCA ontology. | Other: Fields that have are not ontologised and that are validated against other premises. | . We're going to start with the ontologised fields. Ontologised fields&#182; . These terms are called &quot;ontologised&quot; because they are validated against a set of restrictions defined both in our validation rules and enforced in the ontologies themselves; for example, organ validates that the term used as an input is validated as a child term, only with relationship subclassOf, of the term anatomical structure(UBERON:0000061). Detailed information on the restrictions can be found in the readme file. In this category, we have 2 fields: . | organ: A list of the organs used in this experiment; for this notebook, we're going to use the terms &quot;lung&quot;(UBERON:0002048) and &quot;heart&quot;(UBERON:0000948). | technology: A list of the library preparation technologies used in this experiment; for this notebook, we're going to use the terms 10x 3' v2(EFO:0009899) and 10x 3' v3(EFO:0009922). This field also accepts free text in case there is no ontology for the term just yet; we are also going to add an entry for this | . In&nbsp;[&nbsp;]: # Set up organ organ = { &quot;ontologies&quot;: [ { &quot;text&quot;: &quot;lung&quot;, # Text field, free string that allows the user to introduce a more exact definition of the term if not available in the ontology &quot;ontology&quot;: &quot;UBERON:0002048&quot;, # Unique identifier for the ontology term, in the form of &lt;ontology&gt;:&lt;ID&gt; &quot;ontology_label&quot;: &quot;lung&quot; # Text field, must exactly match the label provided in the ontology, case sensitive. }, { &quot;text&quot;: &quot;heart&quot;, &quot;ontology&quot;: &quot;UBERON:0000948&quot;, &quot;ontology_label&quot;: &quot;heart&quot; } ] } # Set up technology technology = { &quot;ontologies&quot;: [ { &quot;text&quot;: &quot;10x 3&#39; v2&quot;, &quot;ontology&quot;: &quot;EFO:0009899&quot;, &quot;ontology_label&quot;: &quot;10x 3&#39; v2&quot; }, { &quot;text&quot;: &quot;10x 3&#39; v3&quot;, &quot;ontology&quot;: &quot;EFO:0009922&quot;, &quot;ontology_label&quot;: &quot;10x 3&#39; v3&quot; } ], &quot;others&quot;: [ &quot;Mysupercoollibrarypreptechnology&quot; # Free text field to introduce as many terms as you want that couldn&#39;t be found in the ontology ] } # pass the values to our variable minimum_required_fields[&#39;organ&#39;] = organ minimum_required_fields[&#39;technology&#39;] = technology . Other fields&#182; . In&nbsp;[&nbsp;]: # Dates # Dates must follow the following format: YYYY-MM-DDThh:mm:ssZ minimum_required_fields[&#39;releaseDate&#39;] = &quot;2022-08-30T00:00:00Z&quot; minimum_required_fields[&#39;accessionDate&#39;] = &quot;2022-08-30T00:00:00Z&quot; # Enum values # Set of values accepted are predetermined, depending on the field. # For the full list of values, please refer to the readme minimum_required_fields[&#39;dataAccess&#39;] = { &quot;type&quot;: &quot;All fully open&quot;, &quot;notes&quot;: &quot;Can be released publicly! :D&quot; } minimum_required_fields[&#39;identifyingOrganisms&#39;] = [&quot;Human&quot;, &quot;Mouse&quot;, &quot;Other&quot;] minimum_required_fields[&#39;wranglingPriority&#39;] = 1 # Very important project! minimum_required_fields[&#39;wranglingState&#39;] = &quot;Eligible&quot; # Simple values # Set of fields that have a simple value; it may be a free string, an integer or a boolean minimum_required_fields[&#39;cellCount&#39;] = 17500 minimum_required_fields[&#39;primaryWrangler&#39;] = ingest_project[&#39;user&#39;] # User ID is required in this field. minimum_required_fields[&#39;wranglingNotes&#39;] = &quot;This is an awesome project and I will finish it soon&quot; minimum_required_fields[&#39;isInCatalogue&#39;] = True # We want the project to be displayed in the project catalogue . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Create-a-project",
    "relUrl": "/docs/create_a_project/create_a_project.html#Create-a-project"
  },
  "8": {
    "doc": "Create a project in Ingest",
    "title": "Updating project with missing information&#182;",
    "content": "Now that we understand the metadata that we are handling, and that we have filled in the missing bits necessary for a minimum information project, we will update the project with the values that we have been gathering. Once we have the content that we have to update, the update itself is pretty easy! . In&nbsp;[&nbsp;]: # TODO: create update_entity_by_uuid(self, entity_type, uuid, patch) # Retrieve project URL to update ingest_project_url = ingest_project[&#39;_links&#39;][&#39;self&#39;][&#39;href&#39;] response = api.patch(url=ingest_project_url, json=minimum_required_fields) updated_ingest_project = response.json() . Let's print the project and check if the changes have made it through! . In&nbsp;[&nbsp;]: updated_ingest_project . Out[&nbsp;]: {&#39;content&#39;: {&#39;describedBy&#39;: &#39;https://schema.staging.data.humancellatlas.org/type/project/17.0.0/project&#39;, &#39;schema_type&#39;: &#39;project&#39;, &#39;project_core&#39;: {&#39;project_short_name&#39;: &#39;myCoolLabel&#39;, &#39;project_title&#39;: &#39;Test_project_with_minimum_information&#39;, &#39;project_description&#39;: &#39;This is a test project with minimum information for the programmatic submissions guide&#39;}, &#39;contributors&#39;: [{&#39;name&#39;: &#39;Enrique,,Ventura&#39;, &#39;email&#39;: &#39;enrique@ebi.ac.uk&#39;, &#39;institution&#39;: &#39;EMBL-EBI&#39;, &#39;corresponding_contributor&#39;: True, &#39;project_role&#39;: {&#39;text&#39;: &#39;data curator&#39;, &#39;ontology&#39;: &#39;EFO:0009737&#39;, &#39;ontology_label&#39;: &#39;data curator&#39;}}], &#39;publications&#39;: [{&#39;authors&#39;: [&#39;Lorem IP&#39;, &#39;Sed UP&#39;], &#39;title&#39;: &#39;A combined approach for single-cell mRNA and intracellular protein expression analysis&#39;, &#39;url&#39;: &#39;https://www.frontiersin.org/articles/10.3389/fcell.2020.00384/full&#39;, &#39;official_hca_publication&#39;: False}], &#39;funders&#39;: [{&#39;grant_title&#39;: &#39;a cool grant&#39;, &#39;grant_id&#39;: &#39;000000000bp1&#39;, &#39;organization&#39;: &#39;EMBL-EBI&#39;}]}, &#39;submissionDate&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;updateDate&#39;: &#39;2022-09-12T11:21:35.527847Z&#39;, &#39;user&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;lastModifiedUser&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;type&#39;: &#39;Project&#39;, &#39;uuid&#39;: {&#39;uuid&#39;: &#39;dd576596-a8a4-41c1-b402-c46a4ca04395&#39;}, &#39;events&#39;: [], &#39;firstDcpVersion&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;dcpVersion&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;contentLastModified&#39;: &#39;2022-09-12T11:20:46.004Z&#39;, &#39;accession&#39;: None, &#39;validationState&#39;: &#39;Valid&#39;, &#39;validationErrors&#39;: [], &#39;graphValidationErrors&#39;: None, &#39;isUpdate&#39;: False, &#39;releaseDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;accessionDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;technology&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#34;10x 3&#39; v2&#34;, &#39;ontology&#39;: &#39;EFO:0009899&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v2&#34;}, {&#39;text&#39;: &#34;10x 3&#39; v3&#34;, &#39;ontology&#39;: &#39;EFO:0009922&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v3&#34;}], &#39;others&#39;: [&#39;Mysupercoollibrarypreptechnology&#39;]}, &#39;organ&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#39;lung&#39;, &#39;ontology&#39;: &#39;UBERON:0002048&#39;, &#39;ontology_label&#39;: &#39;lung&#39;}, {&#39;text&#39;: &#39;heart&#39;, &#39;ontology&#39;: &#39;UBERON:0000948&#39;, &#39;ontology_label&#39;: &#39;heart&#39;}]}, &#39;cellCount&#39;: 17500, &#39;dataAccess&#39;: {&#39;type&#39;: &#39;All fully open&#39;, &#39;notes&#39;: &#39;Can be released publicly! :D&#39;}, &#39;identifyingOrganisms&#39;: [&#39;Human&#39;, &#39;Mouse&#39;, &#39;Other&#39;], &#39;primaryWrangler&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;secondaryWrangler&#39;: None, &#39;wranglingState&#39;: &#39;Eligible&#39;, &#39;wranglingPriority&#39;: 1, &#39;wranglingNotes&#39;: &#39;This is an awesome project and I will finish it soon&#39;, &#39;isInCatalogue&#39;: True, &#39;cataloguedDate&#39;: &#39;2022-09-12T11:21:35.526573Z&#39;, &#39;publicationsInfo&#39;: None, &#39;dcpReleaseNumber&#39;: None, &#39;projectLabels&#39;: None, &#39;hasOpenSubmission&#39;: False, &#39;_links&#39;: {&#39;self&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;}, &#39;project&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;, &#39;title&#39;: &#39;A single project&#39;}, &#39;processing&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/processingEvent&#39;}, &#39;draft&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/draftEvent&#39;}, &#39;bundleManifests&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/bundleManifests&#39;, &#39;title&#39;: &#39;Access or create bundle manifests (describing which submitted contents went into which bundle in the datastore)&#39;}, &#39;auditLogs&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/auditLogs&#39;}, &#39;supplementaryFiles&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/supplementaryFiles&#39;}, &#39;submissionEnvelopes&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelopes&#39;, &#39;title&#39;: &#39;Access or create new submission envelopes&#39;}, &#39;submissionEnvelope&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelope&#39;, &#39;title&#39;: &#39;A single submission envelope&#39;}}} . And we have our project, updated, with the minimum required metadata! . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Updating-project-with-missing-information",
    "relUrl": "/docs/create_a_project/create_a_project.html#Updating-project-with-missing-information"
  },
  "9": {
    "doc": "Create a project in Ingest",
    "title": "Retrieve a project&#182;",
    "content": "Once we have created a project with minimum information, we may want to retrieve the project to do further things with it (Add more metadata, check status, etc). In order to do this, we are going to use one of the many functions that we have available to retrieve a project: . | IngestApi.get_project_by_uuid: Retrieves a single project with a UUID | . But there are other functions available, in case you don't have the UUID at hand or can't remember, listed below: . Functions to search for projects . | .get_user_projects: Retrieve all the projects associated with your user (Requires token to be set) | .get_project_by_id: Retrieve a project with the MongoDB ID provided | . In&nbsp;[&nbsp;]: ingest_project = api.get_project_by_uuid(ingest_project_uuid) . Let's ensure we have retrieved our project correctly: . In&nbsp;[&nbsp;]: ingest_project . Out[&nbsp;]: {&#39;content&#39;: {&#39;describedBy&#39;: &#39;https://schema.staging.data.humancellatlas.org/type/project/17.0.0/project&#39;, &#39;schema_type&#39;: &#39;project&#39;, &#39;project_core&#39;: {&#39;project_short_name&#39;: &#39;myCoolLabel&#39;, &#39;project_title&#39;: &#39;Test_project_with_minimum_information&#39;, &#39;project_description&#39;: &#39;This is a test project with minimum information for the programmatic submissions guide&#39;}, &#39;contributors&#39;: [{&#39;name&#39;: &#39;Enrique,,Ventura&#39;, &#39;email&#39;: &#39;enrique@ebi.ac.uk&#39;, &#39;institution&#39;: &#39;EMBL-EBI&#39;, &#39;corresponding_contributor&#39;: True, &#39;project_role&#39;: {&#39;text&#39;: &#39;data curator&#39;, &#39;ontology&#39;: &#39;EFO:0009737&#39;, &#39;ontology_label&#39;: &#39;data curator&#39;}}], &#39;publications&#39;: [{&#39;authors&#39;: [&#39;Lorem IP&#39;, &#39;Sed UP&#39;], &#39;title&#39;: &#39;A combined approach for single-cell mRNA and intracellular protein expression analysis&#39;, &#39;url&#39;: &#39;https://www.frontiersin.org/articles/10.3389/fcell.2020.00384/full&#39;, &#39;official_hca_publication&#39;: False}], &#39;funders&#39;: [{&#39;grant_title&#39;: &#39;a cool grant&#39;, &#39;grant_id&#39;: &#39;000000000bp1&#39;, &#39;organization&#39;: &#39;EMBL-EBI&#39;}]}, &#39;submissionDate&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;updateDate&#39;: &#39;2022-09-12T11:21:35.527Z&#39;, &#39;user&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;lastModifiedUser&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;type&#39;: &#39;Project&#39;, &#39;uuid&#39;: {&#39;uuid&#39;: &#39;dd576596-a8a4-41c1-b402-c46a4ca04395&#39;}, &#39;events&#39;: [], &#39;firstDcpVersion&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;dcpVersion&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;contentLastModified&#39;: &#39;2022-09-12T11:20:46.004Z&#39;, &#39;accession&#39;: None, &#39;validationState&#39;: &#39;Valid&#39;, &#39;validationErrors&#39;: [], &#39;graphValidationErrors&#39;: None, &#39;isUpdate&#39;: False, &#39;releaseDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;accessionDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;technology&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#34;10x 3&#39; v2&#34;, &#39;ontology&#39;: &#39;EFO:0009899&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v2&#34;}, {&#39;text&#39;: &#34;10x 3&#39; v3&#34;, &#39;ontology&#39;: &#39;EFO:0009922&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v3&#34;}], &#39;others&#39;: [&#39;Mysupercoollibrarypreptechnology&#39;]}, &#39;organ&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#39;lung&#39;, &#39;ontology&#39;: &#39;UBERON:0002048&#39;, &#39;ontology_label&#39;: &#39;lung&#39;}, {&#39;text&#39;: &#39;heart&#39;, &#39;ontology&#39;: &#39;UBERON:0000948&#39;, &#39;ontology_label&#39;: &#39;heart&#39;}]}, &#39;cellCount&#39;: 17500, &#39;dataAccess&#39;: {&#39;type&#39;: &#39;All fully open&#39;, &#39;notes&#39;: &#39;Can be released publicly! :D&#39;}, &#39;identifyingOrganisms&#39;: [&#39;Human&#39;, &#39;Mouse&#39;, &#39;Other&#39;], &#39;primaryWrangler&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;secondaryWrangler&#39;: None, &#39;wranglingState&#39;: &#39;Eligible&#39;, &#39;wranglingPriority&#39;: 1, &#39;wranglingNotes&#39;: &#39;This is an awesome project and I will finish it soon&#39;, &#39;isInCatalogue&#39;: True, &#39;cataloguedDate&#39;: &#39;2022-09-12T11:21:35.526Z&#39;, &#39;publicationsInfo&#39;: None, &#39;dcpReleaseNumber&#39;: None, &#39;projectLabels&#39;: None, &#39;hasOpenSubmission&#39;: False, &#39;_links&#39;: {&#39;self&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;}, &#39;project&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;, &#39;title&#39;: &#39;A single project&#39;}, &#39;processing&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/processingEvent&#39;}, &#39;draft&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/draftEvent&#39;}, &#39;bundleManifests&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/bundleManifests&#39;, &#39;title&#39;: &#39;Access or create bundle manifests (describing which submitted contents went into which bundle in the datastore)&#39;}, &#39;auditLogs&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/auditLogs&#39;}, &#39;supplementaryFiles&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/supplementaryFiles&#39;}, &#39;submissionEnvelopes&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelopes&#39;, &#39;title&#39;: &#39;Access or create new submission envelopes&#39;}, &#39;submissionEnvelope&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelope&#39;, &#39;title&#39;: &#39;A single submission envelope&#39;}}} . Check status of a project&#182; . When a project (or any piece of metadata) is updated to ingest, it gets validated, the content being validated against the schema it is pointing to (on the describedBy field), and in the case of the project, the base fields validating against other set of rules. The ingest service has the ability to provide with a full report of these validation events, including the status of the entity and the error messages. On this section, we will focus on retrieving the errors (currently none) of the project we just uploaded and we will update the project to artificially produce a couple of errors. We will then retrieve the project again and check on the errors, but for a detailed explanation of each type of error, please refer to the Readme file. In&nbsp;[&nbsp;]: # Print validation errors validation_errors = ingest_project[&#39;validationErrors&#39;] print(f&quot;Validation errors: {validation_errors if validation_errors else None}&quot;) # Print validation status validation_status = ingest_project[&#39;validationState&#39;] print(f&quot;Validation status: {validation_status}&quot;) . Validation errors: None Validation status: Valid . In&nbsp;[&nbsp;]: non_valid_content = ingest_project[&#39;content&#39;] non_valid_content[&#39;estimated_cell_count&#39;] = &#39;17500&#39; # Cell count should always be an integer non_valid_content[&#39;insdc_project_accessions&#39;] = [ # INSDC project accessions: &#39;GSE7777777&#39;, # SHOULD NOT be a GEO series accession &#39;SRP000000&#39;, # SHOULD follow SRPXXXXXX format &#39;&#39;, # SHOULD NOT be an empty string 347289347 # SHOULD NOT be a numer ] non_valid_values = { &quot;content&quot; : non_valid_content # Patching &quot;content&quot; field } # Patch the non_valid content into the project content response = api.patch(url=ingest_project_url, json=non_valid_values) . In&nbsp;[&nbsp;]: response.json() . Out[&nbsp;]: {&#39;content&#39;: {&#39;describedBy&#39;: &#39;https://schema.staging.data.humancellatlas.org/type/project/17.0.0/project&#39;, &#39;schema_type&#39;: &#39;project&#39;, &#39;project_core&#39;: {&#39;project_short_name&#39;: &#39;myCoolLabel&#39;, &#39;project_title&#39;: &#39;Test_project_with_minimum_information&#39;, &#39;project_description&#39;: &#39;This is a test project with minimum information for the programmatic submissions guide&#39;}, &#39;contributors&#39;: [{&#39;name&#39;: &#39;Enrique,,Ventura&#39;, &#39;email&#39;: &#39;enrique@ebi.ac.uk&#39;, &#39;institution&#39;: &#39;EMBL-EBI&#39;, &#39;corresponding_contributor&#39;: True, &#39;project_role&#39;: {&#39;text&#39;: &#39;data curator&#39;, &#39;ontology&#39;: &#39;EFO:0009737&#39;, &#39;ontology_label&#39;: &#39;data curator&#39;}}], &#39;publications&#39;: [{&#39;authors&#39;: [&#39;Lorem IP&#39;, &#39;Sed UP&#39;], &#39;title&#39;: &#39;A combined approach for single-cell mRNA and intracellular protein expression analysis&#39;, &#39;url&#39;: &#39;https://www.frontiersin.org/articles/10.3389/fcell.2020.00384/full&#39;, &#39;official_hca_publication&#39;: False}], &#39;funders&#39;: [{&#39;grant_title&#39;: &#39;a cool grant&#39;, &#39;grant_id&#39;: &#39;000000000bp1&#39;, &#39;organization&#39;: &#39;EMBL-EBI&#39;}], &#39;estimated_cell_count&#39;: &#39;17500&#39;, &#39;insdc_project_accessions&#39;: [&#39;GSE7777777&#39;, &#39;SRP000000&#39;, &#39;&#39;, 347289347]}, &#39;submissionDate&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;updateDate&#39;: &#39;2022-09-12T11:22:02.174371Z&#39;, &#39;user&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;lastModifiedUser&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;type&#39;: &#39;Project&#39;, &#39;uuid&#39;: {&#39;uuid&#39;: &#39;dd576596-a8a4-41c1-b402-c46a4ca04395&#39;}, &#39;events&#39;: [], &#39;firstDcpVersion&#39;: &#39;2022-09-12T11:20:46.006Z&#39;, &#39;dcpVersion&#39;: &#39;2022-09-12T11:22:02.173701Z&#39;, &#39;contentLastModified&#39;: &#39;2022-09-12T11:22:02.173701Z&#39;, &#39;accession&#39;: None, &#39;validationState&#39;: &#39;Valid&#39;, &#39;validationErrors&#39;: [], &#39;graphValidationErrors&#39;: None, &#39;isUpdate&#39;: False, &#39;releaseDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;accessionDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;technology&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#34;10x 3&#39; v2&#34;, &#39;ontology&#39;: &#39;EFO:0009899&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v2&#34;}, {&#39;text&#39;: &#34;10x 3&#39; v3&#34;, &#39;ontology&#39;: &#39;EFO:0009922&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v3&#34;}], &#39;others&#39;: [&#39;Mysupercoollibrarypreptechnology&#39;]}, &#39;organ&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#39;lung&#39;, &#39;ontology&#39;: &#39;UBERON:0002048&#39;, &#39;ontology_label&#39;: &#39;lung&#39;}, {&#39;text&#39;: &#39;heart&#39;, &#39;ontology&#39;: &#39;UBERON:0000948&#39;, &#39;ontology_label&#39;: &#39;heart&#39;}]}, &#39;cellCount&#39;: 17500, &#39;dataAccess&#39;: {&#39;type&#39;: &#39;All fully open&#39;, &#39;notes&#39;: &#39;Can be released publicly! :D&#39;}, &#39;identifyingOrganisms&#39;: [&#39;Human&#39;, &#39;Mouse&#39;, &#39;Other&#39;], &#39;primaryWrangler&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;secondaryWrangler&#39;: None, &#39;wranglingState&#39;: &#39;Eligible&#39;, &#39;wranglingPriority&#39;: 1, &#39;wranglingNotes&#39;: &#39;This is an awesome project and I will finish it soon&#39;, &#39;isInCatalogue&#39;: True, &#39;cataloguedDate&#39;: &#39;2022-09-12T11:21:35.526Z&#39;, &#39;publicationsInfo&#39;: None, &#39;dcpReleaseNumber&#39;: None, &#39;projectLabels&#39;: None, &#39;hasOpenSubmission&#39;: False, &#39;_links&#39;: {&#39;self&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;}, &#39;project&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb&#39;, &#39;title&#39;: &#39;A single project&#39;}, &#39;processing&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/processingEvent&#39;}, &#39;draft&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/draftEvent&#39;}, &#39;bundleManifests&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/bundleManifests&#39;, &#39;title&#39;: &#39;Access or create bundle manifests (describing which submitted contents went into which bundle in the datastore)&#39;}, &#39;auditLogs&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/auditLogs&#39;}, &#39;supplementaryFiles&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/supplementaryFiles&#39;}, &#39;submissionEnvelopes&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelopes&#39;, &#39;title&#39;: &#39;Access or create new submission envelopes&#39;}, &#39;submissionEnvelope&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/631f160e925813602e4993bb/submissionEnvelope&#39;, &#39;title&#39;: &#39;A single submission envelope&#39;}}} . After patching the project with invalid values, let's repeat the check we did previously. In&nbsp;[&nbsp;]: ingest_project = api.get_project_by_uuid(ingest_project_uuid) # Print validation errors validation_errors = ingest_project[&#39;validationErrors&#39;] newline = &#39;\\n&#39; print(f&quot;Validation errors: {validation_errors if validation_errors else None}&quot;) # Print validation status validation_status = ingest_project[&#39;validationState&#39;] print(f&quot;Validation status: {validation_status}&quot;) . Validation errors: [{&#39;errorType&#39;: &#39;METADATA_ERROR&#39;, &#39;message&#39;: &#39;should match pattern &#34;^[D|E|S]RP[0-9]+$&#34;&#39;, &#39;userFriendlyMessage&#39;: &#39;should match pattern &#34;^[D|E|S]RP[0-9]+$&#34; at .insdc_project_accessions[0]&#39;, &#39;absoluteDataPath&#39;: &#39;.insdc_project_accessions[0]&#39;}, {&#39;errorType&#39;: &#39;METADATA_ERROR&#39;, &#39;message&#39;: &#39;should match pattern &#34;^[D|E|S]RP[0-9]+$&#34;&#39;, &#39;userFriendlyMessage&#39;: &#39;should match pattern &#34;^[D|E|S]RP[0-9]+$&#34; at .insdc_project_accessions[2]&#39;, &#39;absoluteDataPath&#39;: &#39;.insdc_project_accessions[2]&#39;}, {&#39;errorType&#39;: &#39;METADATA_ERROR&#39;, &#39;message&#39;: &#39;should be string&#39;, &#39;userFriendlyMessage&#39;: &#39;should be string at .insdc_project_accessions[3]&#39;, &#39;absoluteDataPath&#39;: &#39;.insdc_project_accessions[3]&#39;}, {&#39;errorType&#39;: &#39;METADATA_ERROR&#39;, &#39;message&#39;: &#39;should be integer&#39;, &#39;userFriendlyMessage&#39;: &#39;should be integer at .estimated_cell_count&#39;, &#39;absoluteDataPath&#39;: &#39;.estimated_cell_count&#39;}] Validation status: Invalid . As we can see, this time it has returned 2 things: . | A set of errors, comprised in a list that details the errors, from type to message. | Validation status: invalid, indicating that the validation went wrong. | . For detailed information on how to understand the errors, please proceed to the &quot;readme.md&quot; file. ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Retrieve-a-project",
    "relUrl": "/docs/create_a_project/create_a_project.html#Retrieve-a-project"
  },
  "10": {
    "doc": "Create a project in Ingest",
    "title": "Delete a project&#182;",
    "content": "Projects in our database can be deleted. While we do not advise to delete projects once they have been published in the data portal (uuid identifiers are important for updates), at any point before finishing the submission (Later in the notebook), any metadata entity can be deleted, including projects. In&nbsp;[&nbsp;]: # TODO: add delete_entity_by_uuid(self, entity_type, uuid) # Delete ingest project and check everything went correctly response = api.delete(ingest_project_url) assert response.status_code == 204 . If the status code of the response is 204, the project has been deleted! . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Delete-a-project",
    "relUrl": "/docs/create_a_project/create_a_project.html#Delete-a-project"
  },
  "11": {
    "doc": "Create a project in Ingest",
    "title": "Addendum&#182;",
    "content": " ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Addendum",
    "relUrl": "/docs/create_a_project/create_a_project.html#Addendum"
  },
  "12": {
    "doc": "Create a project in Ingest",
    "title": "Updating projects&#182;",
    "content": "Deleting a field/Replacing all values&#182; . Deleting a field requires a slightly different sort of operation; up until now, we have used patch to address . Adding new fields&#182; . When adding new fields, considering the type of field that is going to be added is essential; nested properties and arrays can't be just modified through a patch operation, they need the document to be partially (or entirely) replaced . In this notebook, we are going to add 2 fields: . | A completely new field, available in the schema, insdc_project_accessions | A new publication that we want associated to this project, without deleting the already existing one. | . In&nbsp;[&nbsp;]: # Adding the INSDC project accession response = api.patch(url=ingest_project_url, patch={&quot;content&quot;: {&quot;insdc_project_accessions&quot;: [&quot;SRP000000&quot;]}}) assert response.status_code == 200 updated_project = api.get_project_by_uuid(ingest_project_uuid) # Let&#39;s print the project and ensure the modification has gone through! updated_project . Out[&nbsp;]: {&#39;content&#39;: {&#39;insdc_project_accessions&#39;: [&#39;SRP000000&#39;]}, &#39;submissionDate&#39;: &#39;2022-08-31T14:05:37.625Z&#39;, &#39;updateDate&#39;: &#39;2022-08-31T14:07:18.255Z&#39;, &#39;user&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;lastModifiedUser&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;type&#39;: &#39;Project&#39;, &#39;uuid&#39;: {&#39;uuid&#39;: &#39;019b3b05-903b-4b85-bdae-1e10589ccd06&#39;}, &#39;events&#39;: [], &#39;firstDcpVersion&#39;: &#39;2022-08-31T14:05:37.625Z&#39;, &#39;dcpVersion&#39;: &#39;2022-08-31T14:07:18.252Z&#39;, &#39;contentLastModified&#39;: &#39;2022-08-31T14:07:18.252Z&#39;, &#39;accession&#39;: None, &#39;validationState&#39;: &#39;Draft&#39;, &#39;validationErrors&#39;: [], &#39;graphValidationErrors&#39;: None, &#39;isUpdate&#39;: False, &#39;releaseDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;accessionDate&#39;: &#39;2022-08-30T00:00:00Z&#39;, &#39;technology&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#34;10x 3&#39; v2&#34;, &#39;ontology&#39;: &#39;EFO:0009899&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v2&#34;}, {&#39;text&#39;: &#34;10x 3&#39; v3&#34;, &#39;ontology&#39;: &#39;EFO:0009922&#39;, &#39;ontology_label&#39;: &#34;10x 3&#39; v3&#34;}], &#39;others&#39;: [&#39;Mysupercoollibrarypreptechnology&#39;]}, &#39;organ&#39;: {&#39;ontologies&#39;: [{&#39;text&#39;: &#39;lung&#39;, &#39;ontology&#39;: &#39;UBERON:0002048&#39;, &#39;ontology_label&#39;: &#39;lung&#39;}, {&#39;text&#39;: &#39;heart&#39;, &#39;ontology&#39;: &#39;UBERON:0000948&#39;, &#39;ontology_label&#39;: &#39;heart&#39;}]}, &#39;cellCount&#39;: 17500, &#39;dataAccess&#39;: {&#39;type&#39;: &#39;All fully open&#39;, &#39;notes&#39;: &#39;Can be released publicly! :D&#39;}, &#39;identifyingOrganisms&#39;: [&#39;Human&#39;, &#39;Mouse&#39;, &#39;Other&#39;], &#39;primaryWrangler&#39;: &#39;5ece3464ec0680746267e784&#39;, &#39;secondaryWrangler&#39;: None, &#39;wranglingState&#39;: &#39;Eligible&#39;, &#39;wranglingPriority&#39;: 1, &#39;wranglingNotes&#39;: &#39;This is an awesome project and I will finish it soon&#39;, &#39;isInCatalogue&#39;: True, &#39;cataloguedDate&#39;: &#39;2022-08-31T14:06:06.624Z&#39;, &#39;publicationsInfo&#39;: None, &#39;dcpReleaseNumber&#39;: None, &#39;projectLabels&#39;: None, &#39;hasOpenSubmission&#39;: False, &#39;_links&#39;: {&#39;self&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69&#39;}, &#39;project&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69&#39;, &#39;title&#39;: &#39;A single project&#39;}, &#39;validating&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69/validatingEvent&#39;}, &#39;bundleManifests&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69/bundleManifests&#39;, &#39;title&#39;: &#39;Access or create bundle manifests (describing which submitted contents went into which bundle in the datastore)&#39;}, &#39;auditLogs&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69/auditLogs&#39;}, &#39;supplementaryFiles&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69/supplementaryFiles&#39;}, &#39;submissionEnvelopes&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69/submissionEnvelopes&#39;, &#39;title&#39;: &#39;Access or create new submission envelopes&#39;}, &#39;submissionEnvelope&#39;: {&#39;href&#39;: &#39;https://api.ingest.staging.archive.data.humancellatlas.org/projects/630f6ab106f1711fccbe4d69/submissionEnvelope&#39;, &#39;title&#39;: &#39;A single submission envelope&#39;}}} . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Updating-projects",
    "relUrl": "/docs/create_a_project/create_a_project.html#Updating-projects"
  },
  "13": {
    "doc": "Create a project in Ingest",
    "title": "Commmon errors FAQ&#182;",
    "content": "Note: move this to readme . &#182; . In&nbsp;[&nbsp;]: . Interactive view (Notebook) . Download Notebook . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#Commmon-errors-FAQ",
    "relUrl": "/docs/create_a_project/create_a_project.html#Commmon-errors-FAQ"
  },
  "14": {
    "doc": "Create a project in Ingest",
    "title": "Understanding the metadata",
    "content": "In the example above, this is the metadata that we have initially sent: . Project JSON metadata { \"describedBy\": \"https://schema.staging.data.humancellatlas.org/type/project/17.0.0/project\", \"schema_type\": \"project\", \"project_core\": { \"project_short_name\": \"myCoolLabel\", \"project_title\": \"Test_project_with_minimum_information\", \"project_description\": \"This is a test project with minimum information for the programmatic submissions guide\" }, \"contributors\": [ { \"name\": \"Enrique,,Ventura\", \"email\": \"enrique@ebi.ac.uk\", \"institution\": \"EMBL-EBI\", \"corresponding_contributor\": true, \"project_role\": { \"text\": \"data curator\", \"ontology\": \"EFO:0009737\", \"ontology_label\": \"data curator\" } } ], \"publications\": [ { \"authors\": [ \"Lorem IP\", \"Sed UP\" ], \"title\": \"A combined approach for single-cell mRNA and intracellular protein expression analysis\", \"url\": \"https://www.frontiersin.org/articles/10.3389/fcell.2020.00384/full\", \"official_hca_publication\": false } ], \"funders\": [ { \"grant_title\": \"a cool grant\", \"grant_id\": \"000000000bp1\", \"organization\": \"EMBL-EBI\" } ] } . This piece of metadata, in JSON format, is what we call an instance of a schema. These instances point out to the schema it should be validated against, in this case, the project v17.0.0 schema. This schema validates all the necessary information, and this information is what will be submitted downstream (e.g. to the HCA-DCP Data portal). However, the project JSON object has another type of . Schema fields . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#understanding-the-metadata",
    "relUrl": "/docs/create_a_project/create_a_project.html#understanding-the-metadata"
  },
  "15": {
    "doc": "Create a project in Ingest",
    "title": "Creating your own project metadata",
    "content": "The project metadata schema . ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#creating-your-own-project-metadata",
    "relUrl": "/docs/create_a_project/create_a_project.html#creating-your-own-project-metadata"
  },
  "16": {
    "doc": "Create a project in Ingest",
    "title": "Project metadata peculiarities",
    "content": " ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html#project-metadata-peculiarities",
    "relUrl": "/docs/create_a_project/create_a_project.html#project-metadata-peculiarities"
  },
  "17": {
    "doc": "Create a project in Ingest",
    "title": "Create a project in Ingest",
    "content": ". ",
    "url": "http://localhost:4000/docs/create_a_project/create_a_project.html",
    "relUrl": "/docs/create_a_project/create_a_project.html"
  },
  "18": {
    "doc": "Submission guidelines",
    "title": "Submission guidelines",
    "content": " ",
    "url": "http://localhost:4000/docs/docs.html",
    "relUrl": "/docs/docs.html"
  },
  "19": {
    "doc": "Ingest Programmatic Submissions",
    "title": "Ingest Programmatic Submissions",
    "content": " ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "20": {
    "doc": "Basic concepts before start",
    "title": "Programmatic submissions",
    "content": " ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#programmatic-submissions",
    "relUrl": "/docs/introduction/introduction.html#programmatic-submissions"
  },
  "21": {
    "doc": "Basic concepts before start",
    "title": "Purpose of this document",
    "content": "This document is intended to give an introduction to the HCA ingest service, specifically targeting data and metadata in the system and how they interact in the ingest ecosystem of data. These documents will be coupled with a set of python notebooks, which will show examples of how to interact with the data. This is the introductory doc, which will explain the basics behind the metadata schema and the shape/content of the responses the user will obtain interacting with it. ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#purpose-of-this-document",
    "relUrl": "/docs/introduction/introduction.html#purpose-of-this-document"
  },
  "22": {
    "doc": "Basic concepts before start",
    "title": "Terminology",
    "content": ". | HCA: Human Cell Atlas | DCP: Data Coordination Platform | Project: In the context of the HCA DCP Ingest Service, the term project may have one of 2 meanings: . | When referring to metadata, the JSON file that contains the metadata about a project | When referring to a submission/dataset, these 3 terms can be used interchangeably to describe a set of data and metadata that make sense when put together (e.g. all the data from a paper and the metadata that describes it) | . | Entity: In the HCA, an entity is used to describe | Experimental graph: Representation of the experimental model and the relationships between all entities (e.g. provenance) | Subgraph: Minimum unit an experimental graph can be broken down to while still being useful (e.g. All the metadata pieces needed to understand a set of fastq files) | Ingest: Interchangeable with Ingest Service and Ingest Platform | Ontologised: When referred to a field, that it gets validated against a specific ontology. | . ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#terminology",
    "relUrl": "/docs/introduction/introduction.html#terminology"
  },
  "23": {
    "doc": "Basic concepts before start",
    "title": "Table of contents",
    "content": ". | Understanding the metadata schema . | Structure | . | The HCA-DCP Ingestion Service . | What is the HCA-DCP Ingestion Service | What constitutes a project/submission in Ingest | How to interact with Ingest: the API | . | Understanding the JSON files in the system . | Metadata validation . | Ontologised fields | Other type of fields | . | API specification . | content | _links | System-specific fields | More information | . | . | . ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#table-of-contents",
    "relUrl": "/docs/introduction/introduction.html#table-of-contents"
  },
  "24": {
    "doc": "Basic concepts before start",
    "title": "Understanding the metadata schema",
    "content": "The metadata schema is the staple of how data is interpreted in the system; it defines the content, validation rules and structure of all the metadata that is in the system. For the Human Cell Atlas Data Coordination Platform, a JSON schema was chosen to define the metadata in the system. For full details, please refer to the metadata schema SLO and rationale documents. Structure . The metadata schema is structured as stated in the metadata entity model section of the structure.md document of the metadata schema repository. For the purpose of this guide, “type entity” will be used to refer to the subtypes of the 5 major entities in the metadata model: . | Project: Contains information about the project, such as manuscript metadata, grants involved, contributors of the project etc | File: Contains information about the data files, such as filename, description of the content, etc | Biomaterial: Contains information about each of the biological materials used in the project, such as cell suspensions, specimens, etc. | Project: Contains information about each of the protocols used on each step of the experiment. | Process: Contains information about a process; usually, we don’t need to worry a lot about processes, as they are used as intermediates in the system to create the relationships in between the other elements. | . The schemas accepted for each of the major entities can be found always under the url https://github.com/HumanCellAtlas/metadata-schema/tree/master/json_schema/type/{major_entity}, substituting {type} with any of the major types described previously (e.g. https://github.com/HumanCellAtlas/metadata-schema/tree/master/json_schema/type/biomaterial) . ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#understanding-the-metadata-schema",
    "relUrl": "/docs/introduction/introduction.html#understanding-the-metadata-schema"
  },
  "25": {
    "doc": "Basic concepts before start",
    "title": "The HCA-DCP Ingestion Service",
    "content": "What is the HCA-DCP Ingestion Service . The HCA-DCP is composed of several pieces of software that talk to each other, to ensure that the data is ingested, stored and shared. The HCA-DCP Ingestion service constitutes that first step, and it’s on itself the entry door of the data to the DCP; this is the interface that connects the users (Data scientists, data generators) with the data portal. In order to provide with that service, the Ingest Team has defined a data model, based around the entities in the metadata schema. In this model, we have a project (See terminology, project, meaning i), which is usually associated with one or more papers and has information associated with it (see ingest project schema for more information). Within that project, you have 1 or more submissions, and each can be understood as a “data envelope” that packs up a minimal amount of information that needs to be delivered together to e.g. the DCP data portal. As any service, it has different environments for different purposes: . | production: https://api.ingest.archive.data.humancellatlas.org/ | staging: https://api.ingest.staging.archive.data.humancellatlas.org/ | dev: https://api.ingest.dev.archive.data.humancellatlas.org/ | . Each one of these environments points to a different deployment of the platform, and ultimately, a good rule of thumb is that any dataset that needs to be tested first should be brokered first through staging, since the output will not disrupt any of the services downstream. What constitutes a project/submission in Ingest . In the HCA, we understand a project as the minimum expression of data and metadata that is packed together to explain an experimental design and its outputs. Below you can find an example of a whole project with a submission, and how the entities relate to each other: you can click on each of the entities to be redirected to the folder of the metadata schema that contains all the type entities of that class. Most of the relationships allowed by the system are M:N; what this means, is that given the following: . | Biomaterial/file | Process | . All of the following scenarios are possible . graph TD; A[Specimen 1]--&gt;B[Dissociation process]; C[Specimen 2]--&gt;B; B--&gt;D[Pooled cell suspension]; E[Specimen 1]--&gt;F[Dissociation process] E--&gt;I[Dissociation process 2] F--&gt;H[Cell suspension 1] I--&gt;G[Cell suspension 2] . graph TD; A[Cell suspension 1]--&gt;B[Sequencing process] B--&gt;C[Read 1 sequence file] B--&gt;D[Read 2 sequence file] B--&gt;E[Index 1 sequence file] B--&gt;F[Index 2 sequence file] . A couple of general rules on how experiments are modeled in the HCA: . | The input of a process can be one/several biomaterial/files | The output of a process will be either one biomaterial or one/several files | A process is unique and cannot be used multiple times. | (Not shown in figure) A process can have as many protocols attached as needed | Protocols are attached independently of inputs/outputs | . Please take into account that there are exceptions; these rules apply to our modelling decisions rather than to limitations of our system, so if you feel that these rules do not apply to your experiment, please contact us at the wrangler email. How to interact with Ingest: the API . As any service that stores and surfaces data, the HCA DCP Ingestion service has several ways of floating the metadata. In these guidelines, I will mainly focus on the API, as it will be the only way that the notebook will teach to interact with ingest. The Ingest API is a RESTful API that is formatted in the JSON Hypertext Application Language (HAL), which makes it so that the content returned by the API can be consistently accessed. You can find more information on the consistent fields in the API specification section. ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#the-hca-dcp-ingestion-service",
    "relUrl": "/docs/introduction/introduction.html#the-hca-dcp-ingestion-service"
  },
  "26": {
    "doc": "Basic concepts before start",
    "title": "Understanding the JSON files in the system",
    "content": "Metadata files in the system are stored as JSON entries; more concretely, they are stored as entries in a MongoDB database and exposed through the API. In these guidelines, it will be shown how to use the Ingest client to interact with the API; the client just provides an easy-to-use CLI interface to interact. The next documents will deal with each entity type individually, so what you could expect here is a general understanding that may apply to all the entities, e.g. the specific HAL-related fields that populate the API responses. Metadata validation . The Ingest Service validates the metadata that comes into the system by using the ingest-validator. The platform does all the work for the user, so you don’t need to worry about triggering anything. Ontologised fields . One of the main reasons why Ingest uses a custom JSON schema validation is that many fields are ontologised. In a JSON file, you can recognise an ontologised term because it always presents the next fields: . | text: Free text, for the user to input what’s closest to what they are trying to describe (e.g. Disease status) | ontology: An identifier, in the form of PREFIX:ACCESSION (e.g. PATO:000461). This is the field that will be validated | ontology_label: The label that is officially assigned to that ontology term. | . An example for disease status: . { \"text\": { \"description\": \"The text for the term as the user provides it.\", \"type\": \"string\", \"user_friendly\": \"Disease\", \"example\": \"type 2 diabetes mellitus; normal\" }, \"ontology\": { \"description\": \"An ontology term identifier in the form prefix:accession.\", \"type\": \"string\", \"graph_restriction\": { \"ontologies\": [ \"obo:mondo\", \"obo:efo\", \"obo:hp\" ], \"classes\": [ \"MONDO:0000001\", \"PATO:0000461\", \"HP:0000118\" ], \"relations\": [ \"rdfs:subClassOf\" ], \"direct\": false, \"include_self\": true }, \"user_friendly\": \"Disease ontology ID\", \"example\": \"MONDO:0005148; PATO:0000461; HP:0001397\" }, \"ontology_label\": { \"description\": \"The preferred label for the ontology term referred to in the ontology field. This may differ from the user-supplied value in the text field.\", \"type\": \"string\", \"user_friendly\": \"Disease ontology label\", \"example\": \"type 2 diabetes mellitus; normal\" } } . A couple of key notes about ontologised fields: . | The validator will always look up for terms that are within the HCAO Ontology. | The relations field defines which relationships are accepted under the class (e.g. must be subclass of disease) | The schemas to look up for the ontology restrictions can be found under the module/ontology folder in the HCA Metadata Schema repository. | . Other type of fields . As with any JSON schema, fields can contain many types of values; to find a description of the types of values accepted, please refer to the type-specific keywords documentation in the official JSON Schema webpage. API specification . As a general rule (Except for the project metadata), the user should only worry about the content field, which is the part of the response that will contain the submitted metadata, and the CLI works as an interface so there’s no need to know the rest of the fields. However, in this section, there will be a brief explanation on what fields you will find if you were to inspect the responses. content . This is the metadata that the user has submitted for that specific entity; for a more in-depth explanation, please refer to the specific documents about the 5 types of entities. _links . The content of this field contains all the URIs needed to navigate and interact with the API. These links contain a reference to an endpoint that is related to this entity, which can be used to refer to relationships (e.g. inputToProcesses, self, project, biomaterials, etc) or be used as the URI for a POST/PATCH/PUT request to modify the entity or its relationships. The specific fields will not be detailed here, as they are slightly different for each entity, but there will be an in-depth explanation on the guidelines section about linking entities together. System-specific fields . These fields will be available if you inspect the response of any object in the system: you do not need to worry about them, as Ingest will fill them automatically. For the sake of clarity, here is a brief description for them. | updateDate: Last time the JSON file was updated | user: Who created the file | lastModifiedUser: Who modified the file last | type: Type of entity, must be one of the 5 specified in the structure section | uuid: Universally Unique IDentifier for the entity; assigned at creation | events: OUTDATED Recording of events that the entity have gone through. | firstDcpVersion: First date that the document was created | dcpVersion: Last time the JSON file was updated; same as updateDate | contentLastModified: Last time the METADATA (content) was updated | accession: Accession(s) that is/are associated with this entity | validationState: Validation state of the entity; May be draft, metadata valid, metadata invalid | validationErrors: Collection of validationErrors, associated with the JSON schema validation | graphValidationErrors: Collection of validationErrors, associated with the Ingest graph validator (Covered in a later section) | isUpdate: OUTDATED If this entity is an update. This was used when duplicates were used to update the entities in the system. | linked: If the entity is linked in the system with other entities (e.g. a Biomaterial to a process). | . More information . If you are interested in learning more about the API endpoints and the metadata that each presetns, you can go to the root of the API (Stated here) and travel the endpoints. Please be advised that for most of the endpoints, you will need to retrieve a token. More information on how to obtain a token here. ",
    "url": "http://localhost:4000/docs/introduction/introduction.html#understanding-the-json-files-in-the-system",
    "relUrl": "/docs/introduction/introduction.html#understanding-the-json-files-in-the-system"
  },
  "27": {
    "doc": "Basic concepts before start",
    "title": "Basic concepts before start",
    "content": " ",
    "url": "http://localhost:4000/docs/introduction/introduction.html",
    "relUrl": "/docs/introduction/introduction.html"
  }
}